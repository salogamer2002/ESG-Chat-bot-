# ğŸŒ ESG Compliance Chatbot â€“ Project MÄ«zÄn

A secure, Retrieval-Augmented Generation (RAG) based chatbot that helps **SMEs** understand and comply with **Environmental, Social, and Governance (ESG)** regulations. This AI assistant can parse legal texts, extract region-specific requirements, and answer complex compliance questionsâ€”all while being completely open-source, cloud-agnostic, and self-hostable.

---

## ğŸ“Œ Key Features

- âœ… **RAG-based chatbot** for interactive, accurate legal Q&A
- ğŸ“‚ Ingests and indexes ESG documents in nested folders (~5.6 GB tested)
- ğŸ” Uses FAISS for fast, similarity-based retrieval
- ğŸ§  LangChain-powered orchestration with OpenAI GPT-3.5 Turbo
- ğŸ“Š Embedded legal advisory prototype (rules engine-ready)
- ğŸ’¬ Built-in **Chainlit** chat interface (real-time)
- ğŸ“ **Profile capture system**: Collects user data (name, org, country) on first login
- ğŸ“„ **Document upload & ESG gap analysis** with page-level scoring and recommendations
- ğŸ“ Source-linked answers with PDF URLs (chunk-aware)
- ğŸ” Zero vendor lock-in, local or private cloud deployable

---

## ğŸ§  System Architecture

| Component            | Technology / Description                                              |
|----------------------|----------------------------------------------------------------------|
| **Embedding Model**  | `all-MiniLM-L6-v2` via SentenceTransformers                         |
| **Vector Store**     | FAISS (`IndexHNSWFlat`, 384-dim embeddings)                          |
| **LLM**              | OpenAI GPT-3.5 Turbo (API-based)                                     |
| **Retriever**        | Custom LangChain retriever (top-k=5)                                 |
| **Frontend**         | Chainlit (WebSocket UI for chat + profile handling)                  |
| **Chunking**         | Token-aware using `tiktoken` (max 512 tokens per chunk)              |
| **Gap Analysis**     | Async section-level report generation with compliance scoring        |
| **Storage**          | Filesystem (or MinIO for scalable deployments)                       |
| **Orchestration**    | Docker (dev), Kubernetes via K3s/MicroK8s (prod ready)               |

---

## ğŸ§¾ Documented Use Cases

- â€œWhat is the minimum wage in Bangladesh?â€
- â€œIs maternity leave mandatory in Jordan?â€
- â€œDo we have to disclose worker audits under Saudi ESG rules?â€
- â€œWhat counts as forced labor under ILO conventions?â€
- â€œUpload this policy and give a gap analysisâ€

---

## ğŸ“ Directory Layout

```

esg-chatbot/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ ingest.py # Recursively loads ESG documents from nested folders
â”‚ â”œâ”€â”€ embed.py # Embeds documents & builds FAISS index
â”‚ â”œâ”€â”€ rag_chain.py # Constructs LangChain RetrievalQA chain
â”‚ â”œâ”€â”€ user_db.py # Manages user profile database (SQLite)
â”‚ â”œâ”€â”€ file_analysis.py # Gap analysis engine for uploaded PDFs/DOCX
â”‚ â””â”€â”€ utils.py # Token-aware text chunking
â”œâ”€â”€ data/
â”‚ â””â”€â”€ raw_docs/ # Store original ESG PDFs and documents
â”œâ”€â”€ vector_store/ # Persisted FAISS index
â”œâ”€â”€ chainlit_app.py # Frontend interface with Chainlit
â”œâ”€â”€ requirements.txt # All Python dependencies
â””â”€â”€ .env # OpenAI API key (secured)

````

---

## ğŸ“¦ Installation & Setup

### 1. Clone Repository

```bash
git clone https://github.com/rawahabinkhalid/esg-chatbot.git
cd esg-chatbot
````

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Environment Configuration

Create a `.env` file:

```env
OPENAI_API_KEY=sk-your-openai-key-here

# ğŸŒ OAuth for Google Sign-In (Chainlit)
OAUTH_GOOGLE_CLIENT_ID=your-google-client-id
OAUTH_GOOGLE_CLIENT_SECRET=your-google-client-secret

# ğŸ“Š Optional: Literal API Key (for observability if integrated)
LITERAL_API_KEY=your-literal-api-key

# ğŸ” Chainlit Auth (used for secure sessions)
CHAINLIT_AUTH_SECRET=your-random-secret-string

# ğŸŒ Public-facing chatbot URL (used for profile completion redirect & file links)
URL="https://chat.mizan-ai.com"
```

### 4. Add Your ESG Documents

Place all your ESG files (PDFs, DOCX, TXT) inside:

```
data/raw_docs/
```

Nested directories are fully supported.

---

## ğŸ”§ Preprocessing & Embedding

### Chunking Strategy

* Rule-based with fallback on token count.
* Uses `tiktoken` tokenizer to ensure chunks â‰¤ 512 tokens.
* Chunk metadata includes file path, chunk number, and source.

### Embedding Strategy

* Embedding model: `all-MiniLM-L6-v2` (384 dimensions)
* Vector index: `faiss.IndexHNSWFlat(dim=384, M=32)`
* Metadata stored: `{"source": filepath, "chunk": i}`

### Run Embedding Pipeline

```bash
python -c "from app.embed import embed_documents; embed_documents()"
python -c "from app.embed import add_single_document_to_faiss; add_single_document_to_faiss('mizan-training-sources.md')"
```

This will build a FAISS index at `vector_store/faiss_index`.

---

## ğŸ’¬ Start the Chatbot UI

```bash
uvicorn asgi_app:app --host 0.0.0.0 --port 8000
```

Visit: [https://chat.mizan-ai.com](https://chat.mizan-ai.com)

---

## ğŸ§ª Example Prompts to Try

* â€œWhat are the working hours laws in Jordan?â€
* â€œWhat audit disclosures are required by EU supply chain laws?â€
* â€œDoes Bangladesh mandate grievance redressal mechanisms?â€
* â€œGive maternity leave duration under Saudi ESG guidelines.â€
* â€œAnalyze this uploaded ESG report for compliance issues.â€

---

## ğŸ§± Component Details

### `app/ingest.py`

* Walks through all folders under `data/raw_docs`
* Loads `.pdf`, `.docx`, and `.txt` files
* Extracts text using `PyMuPDF`

### `app/utils.py`

* Breaks down documents into 512-token chunks
* Tokenizer-aware (ensures model compatibility)
* Returns list of clean, context-preserving text chunks

### `app/embed.py`

* Embeds documents using `SentenceTransformers`
* Stores vector data and metadata in local FAISS DB
* Callable standalone from any script

### `app/rag_chain.py`

* Loads FAISS index
* Uses LangChain to construct a RetrievalQA chain
* Injects prompt template with:

  * Top-k context
  * User query
  * Section-citing instruction

### `app/file_analysis.py`

* Performs ESG gap analysis using GPT-3.5
* Breaks documents into page-based chunks
* Evaluates strengths, gaps, improvements, and confidence levels
* Produces detailed final compliance summary

### `chainlit_app.py`

* Handles OAuth login and enforces profile completion
* Connects RAG engine and document evaluator to Chainlit
* Handles chat events via Chainlit
* On user message, runs the LangChain RAG chain
* Streams response back in real-time
* Logs conversations with source metadata

---

## ğŸ§  Prompt Template

```text
You are a compliance assistant for ESG regulations.

User Question: {question}

Relevant legal content:
{context}

Instructions: Answer using only the legal context, cite section where possible.
```

---

## ğŸ›¡ï¸ Security & Hosting

* âœ… Self-hostable (no AWS/GCP required)
* ğŸ”’ API keys are environment-protected
* ğŸ§¾ Optional integration with MinIO for scalable object storage
* ğŸ§â€â™‚ï¸ Local-only inference options possible with vLLM or llama.cpp (future)
* ğŸ›‘ Prompts users not to share sensitive information
* âœ… Logs stored securely (JSONL format by date)

---

## ğŸ”­ Roadmap

| Week | Focus                       | Goals                                       |
| ---- | --------------------------- | ------------------------------------------- |
| 6    | RAG Output Tuning           | Score ranking, pruning long responses       |
| 7    | Advisory Engine Integration | Rule-based YAML/JSON DSL-based suggestions  |
| 8    | UI Feedback & Finalization  | Streamed answers, user feedback logging     |
| 9+   | Beta Test with SMEs         | Iterative testing, multilingual enhancement |

---

## ğŸ”Œ Optional Enhancements

* Stream answers word-by-word using OpenAI streaming API
* Add authentication + per-user FAISS filtering
* Visual summaries or charts (ESG scoring)
* Admin dashboard for auditing chatbot responses
#   E S G - C h a t - b o t -  
 